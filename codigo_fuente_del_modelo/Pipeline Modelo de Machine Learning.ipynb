{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1vFzDyA_FyqeByq1qVph10BtLVG8JvBJb","authorship_tag":"ABX9TyOe9JNFetkJKRBgTvvm3KoY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import files"],"metadata":{"id":"lM2hfXArBwcA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqmJhHlm-5y_"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import joblib\n","\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_score,\n","    recall_score,\n","    f1_score,\n","    roc_auc_score,\n","    confusion_matrix,\n","    classification_report,\n","    precision_recall_curve,\n",")\n","\n","# columnas que esperaba tu notebook ANTES de la ingeniería\n","RAW_FEATURES = [\n","    \"id\",          # puede o no venir\n","    \"age\",         # en días\n","    \"gender\",\n","    \"height\",\n","    \"weight\",\n","    \"ap_hi\",\n","    \"ap_lo\",\n","    \"cholesterol\",\n","    \"gluc\",\n","    \"smoke\",\n","    \"alco\",\n","    \"active\",\n","]\n","\n","\n","class BasicValidator(BaseEstimator, TransformerMixin):\n","    \"\"\"\n","    - Valida que vengan las columnas mínimas.\n","    - Elimina 'id' si viene.\n","    - Verifica que no haya nulos (como en tu notebook, que comprobaste que no había).\n","      Si hay nulos, levantamos un error: así sabes que en producción te mandaron\n","      algo incompleto.\n","    \"\"\"\n","\n","    def __init__(self, required_cols=None, drop_id=True):\n","        self.required_cols = required_cols\n","        self.drop_id = drop_id\n","\n","    def fit(self, X, y=None):\n","        X = X.copy()\n","        self._check_columns(X)\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        self._check_columns(X)\n","\n","        # eliminar id si está\n","        if self.drop_id and \"id\" in X.columns:\n","            X = X.drop(columns=[\"id\"])\n","\n","        # check nulos\n","        if X.isnull().any().any():\n","            null_cols = X.columns[X.isnull().any()].tolist()\n","            raise ValueError(\n","                f\"Se encontraron valores nulos en columnas: {null_cols}. \"\n","                \"El pipeline asume datos completos como en el entrenamiento.\"\n","            )\n","\n","        # check duplicados (como hiciste en el EDA)\n","        # No los eliminamos aquí, solo avisamos.\n","        dups = X.duplicated().sum()\n","        if dups > 0:\n","            # en producción puedes cambiar este print por un log\n","            print(f\"[AVISO] Se encontraron {dups} filas duplicadas en la entrada.\")\n","\n","        return X\n","\n","    def _check_columns(self, X):\n","        if self.required_cols is None:\n","            return\n","        missing = [c for c in self.required_cols if c not in X.columns]\n","        if missing:\n","            raise ValueError(\n","                f\"Faltan columnas requeridas para el modelo: {missing}. \"\n","                f\"Se recibieron: {list(X.columns)}\"\n","            )\n","\n","\n","class ClinicalNormalizer(BaseEstimator, TransformerMixin):\n","    \"\"\"\n","    Replica la lógica de “limpieza clínica” que hiciste:\n","    - altura entre 120 y 220\n","    - peso entre 40 y 200\n","    - ap_hi entre 80 y 250\n","    - ap_lo entre 40 y 140\n","    - ap_hi >= ap_lo\n","\n","    En el notebook eliminabas las filas fuera de rango.\n","    Aquí NO las eliminamos: las CLIPPEAMOS para que el modelo pueda predecir.\n","    \"\"\"\n","\n","    def __init__(self):\n","        # rangos usados en tu notebook\n","        self.height_min, self.height_max = 120, 220\n","        self.weight_min, self.weight_max = 40, 200\n","        self.ap_hi_min, self.ap_hi_max = 80, 250\n","        self.ap_lo_min, self.ap_lo_max = 40, 140\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","\n","        # altura\n","        X[\"height\"] = X[\"height\"].clip(self.height_min, self.height_max)\n","\n","        # peso\n","        X[\"weight\"] = X[\"weight\"].clip(self.weight_min, self.weight_max)\n","\n","        # presiones\n","        X[\"ap_hi\"] = X[\"ap_hi\"].clip(self.ap_hi_min, self.ap_hi_max)\n","        X[\"ap_lo\"] = X[\"ap_lo\"].clip(self.ap_lo_min, self.ap_lo_max)\n","\n","        # asegurar sistólica >= diastólica\n","        mask = X[\"ap_hi\"] < X[\"ap_lo\"]\n","        if mask.any():\n","            # si llega invertido, lo intercambiamos\n","            tmp = X.loc[mask, \"ap_hi\"].copy()\n","            X.loc[mask, \"ap_hi\"] = X.loc[mask, \"ap_lo\"]\n","            X.loc[mask, \"ap_lo\"] = tmp\n","\n","        return X\n","\n","\n","class FeatureEngineer(BaseEstimator, TransformerMixin):\n","    \"\"\"\n","    Hace lo mismo que tú hiciste:\n","    - convertir age (días) -> age_years\n","    - eliminar age\n","    - crear bmi\n","    - crear ap_ratio\n","    \"\"\"\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","\n","        # edad en años\n","        X[\"age_years\"] = (X[\"age\"] / 365).round(1)\n","\n","        # eliminar columna age original\n","        X = X.drop(columns=[\"age\"])\n","\n","        # bmi\n","        X[\"bmi\"] = X[\"weight\"] / ((X[\"height\"] / 100) ** 2)\n","\n","        # relación sistólica/diastólica\n","        X[\"ap_ratio\"] = X[\"ap_hi\"] / X[\"ap_lo\"]\n","\n","        return X\n","\n","\n","class OutlierCapper(BaseEstimator, TransformerMixin):\n","    \"\"\"\n","    Recorta outliers exactamente como en tu notebook:\n","    - bmi: [12, 60]\n","    - ap_hi: max 240\n","    - ap_lo: max 130\n","    - ap_ratio: [1.0, 3.5]\n","    \"\"\"\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","\n","        X[\"bmi\"] = X[\"bmi\"].clip(lower=12, upper=60)\n","        X[\"ap_hi\"] = X[\"ap_hi\"].clip(upper=240)\n","        X[\"ap_lo\"] = X[\"ap_lo\"].clip(upper=130)\n","        X[\"ap_ratio\"] = X[\"ap_ratio\"].clip(lower=1.0, upper=3.5)\n","\n","        return X\n","\n","\n","def main():\n","    # --------------------------------------------------------\n","    # 3.1 Cargar datos (ajusta la ruta a tu entorno)\n","    # --------------------------------------------------------\n","    # En Colab era en Drive. Aquí lo dejamos relativo.\n","    csv_path = \"/content/drive/MyDrive/Machine Learning/Semana 09/application_record.csv\"\n","    df = pd.read_csv(csv_path, sep=\";\")\n","\n","    print(\"Shape original:\", df.shape)\n","    print(\"\\n=== INFO DEL DATASET ===\")\n","    print(df.info())\n","    print(\"\\n=== NULOS ===\")\n","    print(df.isnull().sum().sort_values(ascending=False))\n","    print(\"\\n=== DUPLICADOS ===\")\n","    print(df.duplicated().sum())\n","\n","    # --------------------------------------------------------\n","    # 3.2 Separar X, y\n","    # --------------------------------------------------------\n","    y = df[\"cardio\"].copy()\n","    X = df.drop(columns=[\"cardio\"]).copy()\n","\n","    # --------------------------------------------------------\n","    # 3.3 Definir columnas numéricas a escalar (las mismas que escalaste)\n","    # --------------------------------------------------------\n","    numeric_features = [\n","        \"age_years\",\n","        \"height\",\n","        \"weight\",\n","        \"bmi\",\n","        \"ap_hi\",\n","        \"ap_lo\",\n","        \"ap_ratio\",\n","    ]\n","\n","    # columnas que se dejan pasar tal cual\n","    passthrough_features = [\n","        \"gender\",\n","        \"cholesterol\",\n","        \"gluc\",\n","        \"smoke\",\n","        \"alco\",\n","        \"active\",\n","    ]\n","\n","    # --------------------------------------------------------\n","    # 3.4 Preprocesador de columnas (como tu StandardScaler)\n","    # --------------------------------------------------------\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            (\"num\", StandardScaler(), numeric_features),\n","            (\"cat\", \"passthrough\", passthrough_features),\n","        ],\n","        remainder=\"drop\",\n","    )\n","\n","    # --------------------------------------------------------\n","    # 3.5 Modelo (misma Regresión Logística que usaste)\n","    # --------------------------------------------------------\n","    log_model = LogisticRegression(\n","        solver=\"liblinear\",\n","        class_weight=\"balanced\",\n","        max_iter=1000,\n","        random_state=42,\n","    )\n","\n","    # --------------------------------------------------------\n","    # 3.6 Pipeline COMPLETO\n","    # --------------------------------------------------------\n","    pipeline = Pipeline(\n","        steps=[\n","            (\"validator\", BasicValidator(required_cols=RAW_FEATURES)),\n","            (\"clinical\", ClinicalNormalizer()),\n","            (\"features\", FeatureEngineer()),\n","            (\"outliers\", OutlierCapper()),\n","            (\"preprocess\", preprocessor),\n","            (\"model\", log_model),\n","        ]\n","    )\n","\n","    # --------------------------------------------------------\n","    # 3.7 Train / Test split (mismo 80/20, estratificado)\n","    # --------------------------------------------------------\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X,\n","        y,\n","        test_size=0.2,\n","        random_state=42,\n","        stratify=y,\n","    )\n","\n","    # --------------------------------------------------------\n","    # 3.8 Entrenar\n","    # --------------------------------------------------------\n","    pipeline.fit(X_train, y_train)\n","\n","    # --------------------------------------------------------\n","    # 3.9 Evaluar y encontrar umbral óptimo (como hiciste)\n","    # --------------------------------------------------------\n","    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n","\n","    precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n","    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n","    # el último valor de thresholds no tiene F1, así que ignoramos el nan\n","    best_idx = np.nanargmax(f1_scores)\n","    best_threshold = thresholds[best_idx]\n","\n","    # aplicar umbral\n","    y_pred_opt = (y_pred_proba >= best_threshold).astype(int)\n","\n","    acc = accuracy_score(y_test, y_pred_opt)\n","    prec = precision_score(y_test, y_pred_opt)\n","    rec = recall_score(y_test, y_pred_opt)\n","    f1 = f1_score(y_test, y_pred_opt)\n","    auc = roc_auc_score(y_test, y_pred_proba)\n","\n","    print(\"\\n=== UMBRAL ÓPTIMO ENCONTRADO ===\")\n","    print(f\"Umbral óptimo       : {best_threshold:.3f}\")\n","    print(f\"Precision en umbral : {precisions[best_idx]:.3f}\")\n","    print(f\"Recall en umbral    : {recalls[best_idx]:.3f}\")\n","    print(f\"F1-score en umbral  : {f1_scores[best_idx]:.3f}\")\n","\n","    print(\"\\n=== MÉTRICAS CON UMBRAL ÓPTIMO ===\")\n","    print(f\"Accuracy : {acc:.4f}\")\n","    print(f\"Precision: {prec:.4f}\")\n","    print(f\"Recall   : {rec:.4f}\")\n","    print(f\"F1-score : {f1:.4f}\")\n","    print(f\"ROC-AUC  : {auc:.4f}\")\n","\n","    print(\"\\n=== REPORTE DE CLASIFICACIÓN ===\")\n","    print(classification_report(y_test, y_pred_opt, digits=4))\n","\n","    # --------------------------------------------------------\n","    # 3.10 Guardar en .pkl (pipeline + umbral)\n","    # --------------------------------------------------------\n","    artefacto = {\n","        \"pipeline\": pipeline,\n","        \"threshold\": float(best_threshold),\n","        \"feature_order_info\": {\n","            \"numeric_features\": numeric_features,\n","            \"passthrough_features\": passthrough_features,\n","        },\n","        \"version\": \"1.0.0\",\n","    }\n","\n","    # Guarda el modelo en el directorio actual (/content)\n","    output_path = \"/content/drive/MyDrive/Machine Learning/content/cardio_pipeline.pkl\"\n","    joblib.dump(artefacto, output_path)\n","\n","    print(f\"\\n✅ Modelo guardado correctamente en: {output_path}\")"]},{"cell_type":"markdown","source":[],"metadata":{"id":"UuP2U01hCLtO"}},{"cell_type":"code","source":["\n","# ============================================================\n","# 4. FUNCIÓN DE PREDICCIÓN (USO EN PRODUCCIÓN)\n","# ============================================================\n","\n","def predict_from_raw_dict(list_of_patients, model_path=\"cardio_pipeline.pkl\"):\n","    \"\"\"\n","    list_of_patients: lista de dicts con las columnas crudas tal cual vendrían del sistema.\n","    Ejemplo:\n","    [\n","        {\n","            \"id\": 1,\n","            \"age\": 18393,\n","            \"gender\": 2,\n","            \"height\": 168,\n","            \"weight\": 62,\n","            \"ap_hi\": 110,\n","            \"ap_lo\": 80,\n","            \"cholesterol\": 1,\n","            \"gluc\": 1,\n","            \"smoke\": 0,\n","            \"alco\": 0,\n","            \"active\": 1,\n","        },\n","        ...\n","    ]\n","    \"\"\"\n","    artefacto = joblib.load(\"/content/drive/MyDrive/Machine Learning/Proyecto Machine Learning/cardio_train.csv\")\n","    pipeline = artefacto[\"pipeline\"]\n","    threshold = artefacto[\"threshold\"]\n","\n","    # convertir a DataFrame\n","    df_new = pd.DataFrame(list_of_patients)\n","\n","    # pasar por pipeline\n","    proba = pipeline.predict_proba(df_new)[:, 1]\n","    preds = (proba >= threshold).astype(int)\n","\n","    # devolver como lista de dicts\n","    results = []\n","    for i, row in enumerate(list_of_patients):\n","        results.append(\n","            {\n","                \"input\": row,\n","                \"proba_cardio\": float(proba[i]),\n","                \"pred_cardio\": int(preds[i]),\n","                \"threshold_used\": float(threshold),\n","            }\n","        )\n","    return results\n","\n","\n","# ============================================================\n","# 5. ENTRY POINT\n","# ============================================================\n","if __name__ == \"__main__\":\n","    # 1) entrenamos y guardamos\n","    main()\n","\n","    # 2) ejemplo de uso inmediato con datos crudos (SIN preprocesar)\n","    ejemplo_pacientes = [\n","        {\n","            \"id\": 999,\n","            \"age\": 18393,  # en días\n","            \"gender\": 1,\n","            \"height\": 168,\n","            \"weight\": 62,\n","            \"ap_hi\": 110,\n","            \"ap_lo\": 80,\n","            \"cholesterol\": 1,\n","            \"gluc\": 1,\n","            \"smoke\": 0,\n","            \"alco\": 0,\n","            \"active\": 1,\n","        },\n","        {\n","            \"id\": 1000,\n","            \"age\": 23200,\n","            \"gender\": 2,\n","            \"height\": 160,\n","            \"weight\": 90,\n","            \"ap_hi\": 150,\n","            \"ap_lo\": 100,\n","            \"cholesterol\": 3,\n","            \"gluc\": 1,\n","            \"smoke\": 0,\n","            \"alco\": 0,\n","            \"active\": 1,\n","        },\n","    ]\n","\n","    resultados = predict_from_raw_dict(ejemplo_pacientes, \"/content/drive/MyDrive/Machine Learning/Proyecto Machine Learning/pipeline.pkl\")\n","    print(\"\\n=== PREDICCIONES DE PRUEBA ===\")\n","    for r in resultados:\n","        print(r)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":948},"id":"qhqSSaqR_PxH","executionInfo":{"status":"error","timestamp":1762096116461,"user_tz":300,"elapsed":1167,"user":{"displayName":"EMERSON RONALDO RODRIGUEZ ACEVEDO","userId":"16502710901993245789"}},"outputId":"005cdc47-b3c3-4772-a1f7-c0f9054f1cfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape original: (438557, 1)\n","\n","=== INFO DEL DATASET ===\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 438557 entries, 0 to 438556\n","Data columns (total 1 columns):\n"," #   Column                                                                                                                                                                                                                                                         Non-Null Count   Dtype \n","---  ------                                                                                                                                                                                                                                                         --------------   ----- \n"," 0   ID,CODE_GENDER,FLAG_OWN_CAR,FLAG_OWN_REALTY,CNT_CHILDREN,AMT_INCOME_TOTAL,NAME_INCOME_TYPE,NAME_EDUCATION_TYPE,NAME_FAMILY_STATUS,NAME_HOUSING_TYPE,DAYS_BIRTH,DAYS_EMPLOYED,FLAG_MOBIL,FLAG_WORK_PHONE,FLAG_PHONE,FLAG_EMAIL,OCCUPATION_TYPE,CNT_FAM_MEMBERS  438557 non-null  object\n","dtypes: object(1)\n","memory usage: 3.3+ MB\n","None\n","\n","=== NULOS ===\n","ID,CODE_GENDER,FLAG_OWN_CAR,FLAG_OWN_REALTY,CNT_CHILDREN,AMT_INCOME_TOTAL,NAME_INCOME_TYPE,NAME_EDUCATION_TYPE,NAME_FAMILY_STATUS,NAME_HOUSING_TYPE,DAYS_BIRTH,DAYS_EMPLOYED,FLAG_MOBIL,FLAG_WORK_PHONE,FLAG_PHONE,FLAG_EMAIL,OCCUPATION_TYPE,CNT_FAM_MEMBERS    0\n","dtype: int64\n","\n","=== DUPLICADOS ===\n","0\n"]},{"output_type":"error","ename":"KeyError","evalue":"'cardio'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'cardio'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3871610597.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# 1) entrenamos y guardamos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# 2) ejemplo de uso inmediato con datos crudos (SIN preprocesar)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-273971278.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# 3.2 Separar X, y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# --------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cardio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cardio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'cardio'"]}]},{"cell_type":"code","source":["import joblib\n","import pandas as pd\n","\n","# 1) cargar el artefacto\n","artefacto = joblib.load(\"/content/drive/MyDrive/Machine Learning/Proyecto Machine Learning/pipeline.pkl\")\n","pipeline = artefacto[\"pipeline\"]\n","threshold = artefacto[\"threshold\"]\n","\n","# 2) ejemplo de datos tal cual vienen de tu sistema\n","nuevos = [\n","    {\n","        \"id\": 1,\n","        \"age\": 18393,     # en días\n","        \"gender\": 1,\n","        \"height\": 150,\n","        \"weight\": 62,\n","        \"ap_hi\": 110,\n","        \"ap_lo\": 80,\n","        \"cholesterol\": 1,\n","        \"gluc\": 1,\n","        \"smoke\": 0,\n","        \"alco\": 0,\n","        \"active\": 1,\n","    },\n","    {\n","        \"id\": 2,\n","        \"age\": 19600,\n","        \"gender\": 2,\n","        \"height\": 160,\n","        \"weight\": 90,\n","        \"ap_hi\": 150,\n","        \"ap_lo\": 100,\n","        \"cholesterol\": 3,\n","        \"gluc\": 1,\n","        \"smoke\": 0,\n","        \"alco\": 0,\n","        \"active\": 1,\n","    },\n","]\n","\n","df_new = pd.DataFrame(nuevos)\n","\n","# 3) predecir\n","proba = pipeline.predict_proba(df_new)[:, 1]\n","preds = (proba >= threshold).astype(int)\n","\n","for row, p, y in zip(nuevos, proba, preds):\n","    print(row[\"id\"], \"→ prob:\", round(float(p), 3), \"→ pred:\", int(y))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSxyVUPXHToP","executionInfo":{"status":"ok","timestamp":1762096459038,"user_tz":300,"elapsed":87,"user":{"displayName":"EMERSON RONALDO RODRIGUEZ ACEVEDO","userId":"16502710901993245789"}},"outputId":"f447a7e2-9a1a-4b86-b61a-0a13356456e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 → prob: 0.221 → pred: 0\n","2 → prob: 0.927 → pred: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n"]}]}]}